{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Sheet 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a) (Warm-up): sequential optimisation for eigenvalues\n",
    "Given a symmetric matrix $A=A^\\top \\in \\mathbb{R}^{n \\times n}$ and suppose the first eigenvalue $\\lambda_{\\max}(A)=\\lambda_1(A)$ and eigenvector $\\mathbf{u}_{\\max}\\in\\mathbb{R}^n$, $\\|\\mathbf{u}_{\\max}\\|_2=1$ are known.\n",
    "\n",
    "- Prove that the second eigenvalue $\\lambda_2(A) \\le \\lambda_1(A)$ can be found as\n",
    "$$\n",
    "\\lambda_2(A) = \\max_{\\mathbf{x} \\in \\mathbb{R}^n, \\|\\mathbf{x}\\|_2=1, \\langle \\mathbf{u}_{\\max}, \\mathbf{x} \\rangle = 0}\\langle \\mathbf{x}, A \\mathbf{x} \\rangle,\n",
    "$$\n",
    "and a maximizer \n",
    "$$\n",
    "\\mathbf{x}_* = \\arg\\max_{\\mathbf{x} \\in \\mathbb{R}^n, \\|\\mathbf{x}\\|_2=1, \\langle \\mathbf{u}_{\\max}, \\mathbf{x} \\rangle = 0}\\langle \\mathbf{x}, A \\mathbf{x} \\rangle\n",
    "$$\n",
    "is the corresponding eigenvector.\n",
    "\n",
    "- Suggest how to implement the constraints $\\|\\mathbf{x}\\|_2=1, \\langle \\mathbf{u}_{\\max}, \\mathbf{x} \\rangle = 0$ in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b): Principal Component Analysis\n",
    "Consider a dataset $\\mathbf{X} = \\{\\mathbf{x}_1, \\mathbf{x}_2\\}$, where\n",
    "$$\n",
    "\\mathbf{x}_1 = \\begin{bmatrix}2 \\\\ 1\\end{bmatrix}, \\qquad \\mathbf{x}_2 = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix}.\n",
    "$$\n",
    "- Calculate the PCA matrix $A = \\frac{1}{m}\\sum_{i=1}^{m} \\mathbf{x}_i \\mathbf{x}_i^\\top$.\n",
    "- Calculate the principal component for $r=1$, that is, a vector $\\mathbf{u}\\in\\mathbb{R}^2$, $\\|\\mathbf{u}\\|_2=1$, corresponding to the maximal eigenvalue of $A$.\n",
    "\n",
    "_Hint: Consider $\\mathbf{u} = (v, \\sqrt{1-v^2})^\\top$, $-1\\le v \\le 1$, and solve the variational characterisation problem for $\\lambda_{\\max}(A)$ with respect to $v$._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c): VC-dimension of the halfspaces classifier (lower bound)\n",
    "Consider the halfspaces prediction rule in the homogeneous form,\n",
    "$$\n",
    "h_{\\boldsymbol\\theta}(\\mathbf{x}) = \\mathrm{sign}(\\langle \\boldsymbol\\theta, \\mathbf{x}\\rangle) \\in \\mathcal{H}_n^{hs},\n",
    "$$\n",
    "where $\\mathbf{x} = \\begin{bmatrix}1\\\\ \\mathbf{\\hat x}\\end{bmatrix}$, $\\mathbf{\\hat x} \\in \\mathbb{R}^n$, $\\boldsymbol\\theta \\in \\mathbb{R}^{n+1}.$\n",
    "Consider a dataset \n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}_1 & \\cdots & \\mathbf{x}_{n+1} \\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & 0 \\\\\n",
    "\\vdots & & & \\ddots & & \\vdots \\\\\n",
    "0 & 0 & 0 & \\cdots & 1 & 0 \\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 1\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{(n+1) \\times (n+1)}\n",
    "$$\n",
    "- Show that $\\mathbf{X}$ is shattered by $\\mathcal{H}_n^{hs}$, that is, for any $y_1,\\ldots,y_{n+1} \\in \\{-1,1\\}$ you can find $\\boldsymbol\\theta$ such that $h_{\\boldsymbol\\theta}(\\mathbf{x}_i) = y_i$, $i=1,\\ldots,n+1$.\n",
    "\n",
    "_Hint: you can solve the system of linear equations $\\langle \\boldsymbol\\theta, \\mathbf{x}_i\\rangle = y_i$ exactly, so the $\\mathrm{sign}()$ function is not needed in this case._\n",
    "\n",
    "**Remark:** therefore, $\\text{VC-dim}(\\mathcal{H}_n^{hs}) \\ge n+1$. In fact, one can prove that $\\text{VC-dim}(\\mathcal{H}_n^{hs}) = n+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: PCA computation in Python\n",
    "The following code generates a dataset $X\\in\\mathbb{R}^{2 \\times m}$ of $m=20$ points where each $\\mathbf{x}_i$ is in the form $(x,x+y)^T$, where $x$ is chosen uniformly at random from $[-1,1]$, and $y$ is sampled from the normal distribution with mean zero and variance $0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "X1 = np.random.uniform(low=-1, high=1, size=20)\n",
    "X2 = X1 + np.random.normal(scale=0.1, size=X1.size)\n",
    "X = np.vstack((X1,X2))\n",
    "plt.plot(X[0], X[1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the PCA matrix $A = \\frac{1}{m}\\sum_{i=1}^{m} \\mathbf{x}_i \\mathbf{x}_i^\\top$. _Hint: you can avoid using a `for` loop._\n",
    "- Read about [`numpy.linalg.eigh`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eigh.html) and compute the eigenvector $\\mathbf{u}$ corresponding to the largest eigenvalue of $A$. Does it look close to the $\\mathbf{u}$ calculated in Task (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: compression and recovery of data from PCA\n",
    "- Write a Python code to compress $\\mathbf{x}_i$ into $z_i = \\mathbf{u}^T \\mathbf{x}_i \\in \\mathbb{R}$, $i=1,\\ldots,m$. _(Again, you can use numpy facilities instead of a for loop)_\n",
    "- Write a Python code to reconstruct the approximate data $\\mathbf{\\tilde x}_i = \\mathbf{u} z_i$.\n",
    "- Plot both the original data $X = [\\mathbf{x}_1,\\ldots,\\mathbf{x}_m]$ (you can copy the code from Task 1) and the reconstructed data $\\tilde X = [\\mathbf{\\tilde x}_1,\\ldots,\\mathbf{\\tilde x}_m]$ **on the same plot**. How accurate is the reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
